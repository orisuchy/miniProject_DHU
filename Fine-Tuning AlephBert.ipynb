{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning AlephBert model with Hebrew Decriptive Sentences dataset"
      ],
      "metadata": {
        "id": "8EHSY-R82H8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installations"
      ],
      "metadata": {
        "id": "Mewu02ITouR0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXRZKLUEeRDC"
      },
      "outputs": [],
      "source": [
        "! pip install transformers datasets --quiet\n",
        "!sudo apt-get install git-lfs --quiet\n",
        "!git-lfs install --quiet\n",
        "!pip install wandb --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import Dataset, DatasetDict, load_dataset, load_metric\n",
        "import datasets"
      ],
      "metadata": {
        "id": "Re1ysueEfec4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CB8HSD-27qOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2JrDU4PeRDM"
      },
      "source": [
        "### Load Descriptive_Sentences_He dataset from [Huggingface](https://huggingface.co/datasets/orisuchy/Descriptive_Sentences_He) ü§ó "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "descriptive_dataset = load_dataset(\"orisuchy/Descriptive_Sentences_He\")\n",
        "descriptive_dataset"
      ],
      "metadata": {
        "id": "v980uMEvG7Qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# change all all labels to ID's\n",
        "\"Descriptive\" -> 0\n",
        "<br>\n",
        "\"NotDescriptive\" -> 1\n"
      ],
      "metadata": {
        "id": "Bp3IhKVG3h3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lable2ID(w):\n",
        "  if w[\"label\"] == \"Descriptive\":\n",
        "    w[\"label\"] = 0\n",
        "  else:\n",
        "    w[\"label\"] = 1\n",
        "  return w"
      ],
      "metadata": {
        "id": "7k_JUQ5MV1hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "descriptive_dataset = descriptive_dataset.map(lable2ID)"
      ],
      "metadata": {
        "id": "xAxMnkRPWgNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CefOiZAeRDO"
      },
      "source": [
        "This loads a `DatasetDict` object which you can index into to view an example:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "descriptive_dataset[\"train\"]"
      ],
      "metadata": {
        "id": "nDUKv_rjpyUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHJeKLFneRDP"
      },
      "outputs": [],
      "source": [
        "descriptive_dataset[\"train\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCdb4JWLeRDQ"
      },
      "source": [
        "### Preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcQH8hX9eRDQ"
      },
      "source": [
        "The next step is to tokenize the text into a readable format by the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwmQxQeteRDR"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"onlplab/alephbert-base\")\n",
        "# Other available Hebrew models\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"avichr/heBERT\")\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "tokenizer.tokenize(\"?◊©◊ú◊ï◊ù ◊û◊î ◊†◊©◊û◊¢\", truncation=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx7_2H-IeRDS"
      },
      "source": [
        "A function that will tokenize the text. truncate\n",
        "longer sequences in the text to be no longer than the model's maximum input length:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6TvzzfMeRDS"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ydykki0veRDS"
      },
      "source": [
        "Using ü§ó Datasets `map` function to apply the preprocessing function to the entire dataset. \n",
        "`batched=True` to apply the preprocessing function to multiple elements of the dataset at once for faster\n",
        "preprocessing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ys11DRyeRDT"
      },
      "outputs": [],
      "source": [
        "tokenized_descriptive = descriptive_dataset.map(preprocess_function, batched=True)\n",
        "tokenized_descriptive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzBNe7hneRDU"
      },
      "source": [
        "Padding the text so they are a uniform length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJeUjkkIeRDU"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2VlHbnOeRDU"
      },
      "source": [
        "### Fine-tune with the Trainer API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI1e0Jk9eRDV"
      },
      "source": [
        "Loading [AlephBert](https://huggingface.co/onlplab/alephbert-base) model with the [AutoModelForSequenceClassification](https://huggingface.co/docs/transformers/master/en/model_doc/auto#transformers.AutoModelForSequenceClassification) class along with the number of expected labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPECnvRGeRDV"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"onlplab/alephbert-base\", num_labels=2)\n",
        "# Other available Hebrew models\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(\"avichr/heBERT\", num_labels=2)\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining metric"
      ],
      "metadata": {
        "id": "Xwhgevk_novD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = load_metric(\"accuracy\")\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "  logits, labels = eval_pred\n",
        "  predictions = np.argmax(logits, axis=-1)\n",
        "  # print(f'perd: {predictions} {type(labels)}\\nlabels: {labels} {type(labels)}')\n",
        "  return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# Try other metrices\n",
        "# accuracy_score = load_metric('accuracy')\n",
        "# f1_score = load_metric('f1')\n",
        "# def compute_metrics(eval_pred):\n",
        "#     predictions, labels = eval_pred\n",
        "#     predictions = np.argmax(predictions, axis=1)\n",
        "#     # returns a dict like {'f1':0.54221}\n",
        "#     f1 = f1_score.compute(predictions=predictions, references=labels)\n",
        "#     # returns a dict like {'accuracy': 0.3241}\n",
        "#     acc = accuracy_score.compute(predictions=predictions, references=labels)\n",
        "#     # merge the two dictionaries\n",
        "#     return {**f1, **acc}"
      ],
      "metadata": {
        "id": "YH-vMiAgnjdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining training hyperparameters in [TrainingArguments](https://huggingface.co/docs/transformers/master/en/main_classes/trainer#transformers.TrainingArguments)."
      ],
      "metadata": {
        "id": "WSr7GSc45TbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "path = './finetuning_results'\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=path,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    # label_names = ['Descriptive', 'NotDescriptive'],\n",
        "    report_to=\"wandb\",\n",
        "    logging_steps=48,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    num_train_epochs=12,\n",
        "    weight_decay=0.01,\n",
        ")"
      ],
      "metadata": {
        "id": "rqsLXJCf5PiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passing the training arguments to a [Trainer](https://huggingface.co/docs/transformers/master/en/main_classes/trainer#transformers.Trainer) along with the model, dataset, tokenizer, and data collator."
      ],
      "metadata": {
        "id": "qlGhsQ1H5cnK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsRsIigXeRDW"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_descriptive[\"train\"],\n",
        "    eval_dataset=tokenized_descriptive[\"validation\"],\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling `Trainer.train()` to fine-tune the model."
      ],
      "metadata": {
        "id": "drXuiFUV5qsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "kQf0EfF35uqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uploading to Huggingface"
      ],
      "metadata": {
        "id": "UoPcXLMMxIqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "dLMQP4YNy7iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "git_path = \"orisuchy/Descriptive_Classifier\"\n",
        "trainer.model.push_to_hub(repo_path_or_name=git_path)"
      ],
      "metadata": {
        "id": "5zNuSfHDy_zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing everything**"
      ],
      "metadata": {
        "id": "e7GwGVCh6ZfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading dataset and model"
      ],
      "metadata": {
        "id": "wzMl6ZxMo8zm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading dataset"
      ],
      "metadata": {
        "id": "3mD6QISP6J9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"orisuchy/Descriptive_Sentences_He\")"
      ],
      "metadata": {
        "id": "nsFJObNk3Irj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to convert labels to ID's"
      ],
      "metadata": {
        "id": "SAtb4u_y6zqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def labeltoId(s):\n",
        "  if s == \"Descriptive\":\n",
        "    return 0\n",
        "  else: \n",
        "    return 1  "
      ],
      "metadata": {
        "id": "0w1nG_5r67s4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading model"
      ],
      "metadata": {
        "id": "p0Zzn0hi6Prh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"orisuchy/Descriptive_Classifier\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"orisuchy/Descriptive_Classifier\")"
      ],
      "metadata": {
        "id": "FYx4C1uP6S3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining metric"
      ],
      "metadata": {
        "id": "LaZTu8G-6lsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = datasets.load_metric(\"accuracy\")"
      ],
      "metadata": {
        "id": "GhpIKogt6sQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "qJwzuO1D7RVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "references_lst = []\n",
        "predictions_lst = []\n",
        "for batch in dataset[\"test\"]:\n",
        "  inputs = batch[\"text\"]\n",
        "  reference =  labeltoId(batch[\"label\"])\n",
        "  logits = model(**tokenizer(inputs, return_tensors='pt',truncation=True,padding=True))\n",
        "  prediction = np.argmax(logits, axis=-1)\n",
        "  references_lst.append(reference)\n",
        "  predictions_lst.append(prediction)    \n",
        "score = metric.compute(predictions=np.array(predictions_lst), references=np.array(references_lst))\n",
        "score"
      ],
      "metadata": {
        "id": "oiSAoge97A06"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Copy of final_custom_datasets_V2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}